{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#GUI\n",
    "from tkinter import *\n",
    "from tkinter.filedialog import askopenfilename\n",
    "import tkinter.messagebox\n",
    "import PIL\n",
    "import os\n",
    "from PIL import ImageTk, Image\n",
    "\n",
    "#Model\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import skimage.filters as filters\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import os\n",
    "\n",
    "device = torch.device('cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model(\n",
      "  (layer1): Sequential(\n",
      "    (0): Conv2d(45, 32, kernel_size=(5, 5), stride=(1, 1), padding=(3, 3))\n",
      "    (1): LeakyReLU(negative_slope=0.01)\n",
      "    (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (layer2): Sequential(\n",
      "    (0): Conv2d(32, 64, kernel_size=(5, 5), stride=(1, 1), padding=(3, 3))\n",
      "    (1): LeakyReLU(negative_slope=0.01)\n",
      "    (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (layer3): Sequential(\n",
      "    (0): Conv2d(64, 128, kernel_size=(5, 5), stride=(1, 1), padding=(3, 3))\n",
      "    (1): LeakyReLU(negative_slope=0.01)\n",
      "    (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (drop_out): Dropout(p=0.5)\n",
      "  (ffnn1): Linear(in_features=896, out_features=500, bias=True)\n",
      "  (ffnn2): Linear(in_features=500, out_features=250, bias=True)\n",
      "  (ffnn3): Linear(in_features=250, out_features=24, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "class Model(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Model, self).__init__()\n",
    "        self.layer1=nn.Sequential(\n",
    "            nn.Conv2d(45, 32, kernel_size=5, stride=1, padding=3),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.MaxPool2d(kernel_size = 2, stride=2)\n",
    "        )\n",
    "        self.layer2=nn.Sequential(\n",
    "            nn.Conv2d(32, 64, kernel_size=5, stride=1, padding=3),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        )\n",
    "        self.layer3=nn.Sequential(\n",
    "            nn.Conv2d(64, 128, kernel_size=5, stride=1, padding=3),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        )\n",
    "        self.drop_out = nn.Dropout()\n",
    "        self.ffnn1 = nn.Linear(128*7, 500)\n",
    "        self.ffnn2 = nn.Linear(500, 250)\n",
    "        self.ffnn3 = nn.Linear(250, 24)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        output = self.layer1(x)\n",
    "        output = self.layer2(output)\n",
    "        output = self.layer3(output)\n",
    "        output = output.reshape(output.size(0), -1)\n",
    "        output = self.drop_out(output)\n",
    "        output = self.ffnn1(output)\n",
    "        output = self.ffnn2(output)\n",
    "        output = self.ffnn3(output)\n",
    "        return F.log_softmax(output)\n",
    "    \n",
    "net = Model().to(device)\n",
    "print(net)   \n",
    "def imshow(image, nrows=1, ncols=1, cmap='gray'):\n",
    "    fig, ax = plt.subplots(nrows=nrows, ncols=ncols, figsize=(8, 8))\n",
    "    ax.imshow(image, cmap=cmap)\n",
    "    return fig, ax\n",
    "\n",
    "def define_kernel(kernel_size, std, size):\n",
    "    half_size = kernel_size // 2\n",
    "    kernel = np.zeros([kernel_size, kernel_size])\n",
    "    std_X = std\n",
    "    std_Y = std * size\n",
    "    for i in range(kernel_size):\n",
    "        for j in range(kernel_size):\n",
    "            x = i-half_size\n",
    "            y = i-half_size\n",
    "            \n",
    "            exponent=np.exp(-x**2/(std_X*2)-y**2/(std_Y*2))\n",
    "            x_ = (x**2-std_X**2)/(2*np.pi*std_X**5*std_Y)\n",
    "            y_ = (y**2-std_Y**2)/(2*np.pi*std_Y**5*std_X)\n",
    "            kernel[i, j] = (x_+y_)/exponent\n",
    "    return kernel/np.sum(kernel)\n",
    "\n",
    "def get_category(x):\n",
    "    labels = np.load('Labels_her.npy')\n",
    "    return labels[x]\n",
    "\n",
    "def predict_value(ip, model):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        output = model(ip)\n",
    "        _, predicted = torch.max(output.data, 1)\n",
    "        return get_category(predicted)\n",
    "\n",
    "def recognize_image(image_read):\n",
    "    net = Model()\n",
    "    net.load_state_dict(torch.load('her_model', map_location='cpu'))\n",
    "    print(\"path=\",image_read)\n",
    "    image = cv2.resize(cv2.imread(image_read, cv2.IMREAD_GRAYSCALE), (400, 224))\n",
    "    threshold = filters.threshold_local(image, block_size=195, offset=30)\n",
    "    img = (image > threshold).astype(np.uint8)*255.\n",
    "    kernel = define_kernel(5, 11, 7)\n",
    "    img_filtered = cv2.filter2D(img, -1, kernel, borderType = cv2.BORDER_REPLICATE).astype(np.uint8)\n",
    "    _, img_threshold = cv2.threshold(img_filtered, 0, 255, cv2.THRESH_BINARY+cv2.THRESH_OTSU)\n",
    "    img_threshold = 255-img_threshold\n",
    "    _, components, _=cv2.findContours(img_threshold, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    res = []\n",
    "    for c in components:\n",
    "        if cv2.contourArea(c) < 100:\n",
    "            continue\n",
    "        current_box = cv2.boundingRect(c)\n",
    "        x, y, w, h = current_box\n",
    "        seg_image = img[y:y+h, x:x+w]\n",
    "        res.append((current_box, seg_image))\n",
    "    sort = sorted(res, key=lambda entry:entry[0][0])\n",
    "    predicted = []\n",
    "    for j, w in enumerate(sort):\n",
    "        word_box, _ = w\n",
    "        x, y, w, h = word_box\n",
    "        temp_img = img[y:y+h, x:x+w]/255.\n",
    "        temp_img = cv2.resize(temp_img, (35, 35))\n",
    "        temp_img = cv2.copyMakeBorder(temp_img, 5, 5, 5, 5, cv2.BORDER_CONSTANT, value= [1.])\n",
    "        temp_img = torch.from_numpy(temp_img).float()\n",
    "        temp_img = temp_img.view(-1, 45, 45, 1)\n",
    "        predicted.append(predict_value(temp_img, net))\n",
    "        \n",
    "    return predicted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "win = Tk()\n",
    "win.configure(background = \"WHITE\")\n",
    "win.title(\"Handwritten Equation Recognizer\")\n",
    "win.geometry('800x600')\n",
    "\n",
    "path = os.path.join(os.getcwd(), \"her_banner.png\")\n",
    "\n",
    "def show_image(lbl, lbl2):\n",
    "    image_file = askopenfilename(initialdir = os.getcwd(),\n",
    "                            filetypes = ((\"Image File\", \"*.png *jpg\"),\n",
    "                                        (\"Others\", \"*.*\")\n",
    "                                        ),\n",
    "                            title = \"Select an image\"\n",
    "                           )\n",
    "    \n",
    "    image = ImageTk.PhotoImage(Image.open(image_file).resize((400, 224), Image.ANTIALIAS))\n",
    "    lbl.config(image = image)\n",
    "    lbl.image = image\n",
    "    lbl2.config(text = recognize_image(image_file))\n",
    "    \n",
    "    \n",
    "\n",
    "frame = Frame(win, background = \"WHITE\")\n",
    "frame2 = Frame(win, background = \"WHITE\")\n",
    "label_inputtext = Label(frame, text = \"Opened Image : \", font = (\"Google Sans\", 12),background = \"WHITE\")\n",
    "label_outputtext = Label(frame, text = \"Recognized Characters : \", font = (\"Google Sans\", 12), background = \"WHITE\")\n",
    "label_pred = Label(frame2, text = \" \", font = (\"Google Sans\", 20), background = \"WHITE\")\n",
    "try:\n",
    "    image = ImageTk.PhotoImage(Image.open(path).resize((400, 224), Image.ANTIALIAS))\n",
    "    label = Label(frame, image=image)\n",
    "    label_inputtext.grid(row = 0, column = 0, rowspan = 2, columnspan = 2, sticky = W)\n",
    "    label_outputtext.grid(row = 6, column = 0, rowspan = 2, columnspan=2, sticky = W)\n",
    "    label_pred.grid(row = 10, column = 0, sticky=S)\n",
    "        \n",
    "    label.grid(row = 3, column = 3)\n",
    "    frame.grid()\n",
    "    frame2.grid()\n",
    "except:\n",
    "    lambda: exit()\n",
    "    \n",
    "menu = Menu(win)\n",
    "win.config(menu=menu)\n",
    "file = Menu(menu, tearoff = False)\n",
    "help_ = Menu(menu, tearoff = False)\n",
    "\n",
    "file.add_command(label = \"Load an image\", command = lambda: show_image(label, label_pred))\n",
    "file.add_command(label = \"Exit Application\", command = lambda: exit())\n",
    "\n",
    "help_.add_command(label = \"About Application\", command = lambda: tkinter.messagebox.showinfo(\"About\", \"Handwritten Equation Recognizer Version 0.6-Alpha (2019)\"))\n",
    "\n",
    "menu.add_cascade(label=\"File\", menu=file)\n",
    "menu.add_cascade(label=\"Help\", menu=help_)\n",
    "\n",
    "win.mainloop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
